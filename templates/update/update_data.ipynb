{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update data\n",
    "\n",
    "This notebook downlads recent GitHub activity for a number of organizations.\n",
    "\n",
    "It will extract all issues, PRs, and comments that were updated within a\n",
    "window of interest. It will then save them to disk as CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from update_mod import GitHubGraphQlQuery, extract_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import timedelta\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display\n",
    "import os.path as op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "parameters",
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "fmt = \"{:%Y-%m-%d}\"\n",
    "\n",
    "# Can optionally use number of days to choose dates\n",
    "end_date = pd.datetime.today()\n",
    "\n",
    "github_orgs = [\"jupyterhub\", \"jupyter\", \"jupyterlab\", \"jupyter-widgets\", \"ipython\", \"binder-examples\", \"nteract\"]\n",
    "# github_orgs = ['jupyter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of days to include in plots\n",
    "end_date = pd.to_datetime(end_date)\n",
    "end_date_str = fmt.format(end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GitHub activity\n",
    "\n",
    "Jupyter also has lots of activity across GitHub repositories. The following sections contain\n",
    "overviews of recent activity across the following GitHub organizations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = op.join('..', '..', 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===\n",
      "jupyterhub\n",
      "===\n",
      "\n",
      "\n",
      "Found 147 items, which will take 3 pages\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceb6a51d9c1742c3b9065711abc92afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Downloading:', max=3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 42 items, which will take 1 pages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/choldgraf/anaconda/envs/dev/lib/python3.7/site-packages/ipykernel_launcher.py:48: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/choldgraf/anaconda/envs/dev/lib/python3.7/site-packages/ipykernel_launcher.py:49: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/choldgraf/anaconda/envs/dev/lib/python3.7/site-packages/ipykernel_launcher.py:50: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===\n",
      "jupyter\n",
      "===\n",
      "\n",
      "\n",
      "Found 319 items, which will take 7 pages\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6186353bc0884a72aef48a3e95bd02c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Downloading:', max=7)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 47 items, which will take 1 pages\n",
      "===\n",
      "jupyterlab\n",
      "===\n",
      "\n",
      "\n",
      "Found 2792 items, which will take 56 pages\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f9e8de63dc4be59ebaa821147f797c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Downloading:', max=56)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 51 items, which will take 2 pages\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f0aebd0ca8643d6a258e08143155ce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Downloading:', max=2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===\n",
      "jupyter-widgets\n",
      "===\n",
      "\n",
      "\n",
      "Found 20 items, which will take 1 pages\n",
      "Found 4 items, which will take 1 pages\n",
      "===\n",
      "ipython\n",
      "===\n",
      "\n",
      "\n",
      "Found 30 items, which will take 1 pages\n",
      "Found 13 items, which will take 1 pages\n",
      "===\n",
      "binder-examples\n",
      "===\n",
      "\n",
      "\n",
      "Found 0 items, which will take 0 pages\n",
      "Found no entries for query is:issue user:binder-examples updated:2019-07-29..2019-08-13\n",
      "===\n",
      "nteract\n",
      "===\n",
      "\n",
      "\n",
      "Found 79 items, which will take 2 pages\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "452818737a104cfc8baa59aeb386d4d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Downloading:', max=2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 37 items, which will take 1 pages\n"
     ]
    }
   ],
   "source": [
    "for org in github_orgs:\n",
    "    print(f'===\\n{org}\\n===\\n\\n')\n",
    "    # Load in previous data if we have it\n",
    "    path_data_org = op.join(path_data, org)\n",
    "    path_prs = op.join(path_data_org, 'prs.csv')\n",
    "    path_issues = op.join(path_data_org, 'issues.csv')\n",
    "    path_comments = op.join(path_data_org, 'comments.csv')\n",
    "    prs_old = pd.read_csv(path_prs, index_col=0)\n",
    "    issues_old = pd.read_csv(path_issues, index_col=0)\n",
    "    comments_old = pd.read_csv(path_comments, index_col=0)\n",
    "\n",
    "    # The latest updated time, we'll update `start_date_str` so we don't re-download unnecessarily\n",
    "    latest_date = pd.to_datetime(comments_old['updatedAt'].max())\n",
    "    start_date_str = fmt.format(latest_date)\n",
    "    \n",
    "    # Issues\n",
    "    query_issues = f\"is:issue user:{org} updated:{start_date_str}..{end_date_str}\"\n",
    "    ghq_issues = GitHubGraphQlQuery(query_issues)\n",
    "    ghq_issues.request()\n",
    "    if ghq_issues.data is None:\n",
    "        continue\n",
    "\n",
    "    issues = ghq_issues.data\n",
    "    issues_comments = issues.pop(\"comments\")\n",
    "    issues_comments = extract_comments(issues_comments)\n",
    "    \n",
    "    # Pull Requests\n",
    "    query_prs = f\"is:pr user:{org} created:{start_date_str}..{end_date_str}\"\n",
    "    ghq_prs = GitHubGraphQlQuery(query_prs)\n",
    "    ghq_prs.request()\n",
    "    if ghq_prs.data is None:\n",
    "        continue\n",
    "\n",
    "    prs = ghq_prs.data\n",
    "    prs_comments = prs.pop('comments')\n",
    "    prs_comments = extract_comments(prs_comments)\n",
    "    \n",
    "    # Add a PR-specific field for closed PRs\n",
    "    prs['mergedBy'] = prs['mergedBy'].map(lambda a: a['login'] if a is not None else None)\n",
    "    \n",
    "    # Extract the comments\n",
    "    comments = pd.concat([prs_comments, issues_comments])\n",
    "\n",
    "    # Only keep the comments within our window of interest\n",
    "    comments = comments.query('updatedAt > @start_date_str and updatedAt < @end_date_str')\n",
    "\n",
    "    # Update the data for this org\n",
    "    comments_new = pd.concat([comments_old, comments]).drop_duplicates(subset=['id'], keep='last').sort_values('createdAt', ascending=False)\n",
    "    issues_new = pd.concat([issues_old, issues]).drop_duplicates(subset=['id'], keep='last').sort_values('createdAt', ascending=False)\n",
    "    prs_new = pd.concat([prs_old, prs]).drop_duplicates(subset=['id'], keep='last').sort_values('createdAt', ascending=False)\n",
    "    \n",
    "    # Drop all duplicates\n",
    "    prs_new = prs_new.drop_duplicates()\n",
    "    issues_new = issues_new.drop_duplicates()\n",
    "    comments_new = comments_new.drop_duplicates()\n",
    "    \n",
    "    # Save the data\n",
    "    prs_new.to_csv(op.join(path_data_org, 'prs.csv'))\n",
    "    issues_new.to_csv(op.join(path_data_org, 'issues.csv'))\n",
    "    comments_new.to_csv(op.join(path_data_org, 'comments.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
